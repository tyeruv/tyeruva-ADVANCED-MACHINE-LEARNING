{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQzxFHbQtYos",
        "outputId": "e2c1aba7-4abf-415d-94a6-685ab753153d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n",
            "25000 train sequences\n",
            "25000 test sequences\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "# Load the IMDB dataset\n",
        "max_features = 10000  # Consider only the top 10,000 words\n",
        "maxlen = 150  # Cutoff reviews after 150 words\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "# Restrict training samples to 100\n",
        "x_train = x_train[:100]\n",
        "y_train = y_train[:100]\n",
        "\n",
        "# Pad sequences to the same length\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Validate on 10,000 samples\n",
        "x_val = x_test[:10000]\n",
        "y_val = y_test[:10000]\n",
        "x_test = x_test[10000:]\n",
        "y_test = y_test[10000:]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the RNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Add an embedding layer\n",
        "model.add(Embedding(max_features, 32))  # Embedding layer with 32-dimensional embeddings\n",
        "\n",
        "# Add a bidirectional SimpleRNN layer\n",
        "model.add(Bidirectional(SimpleRNN(32)))\n",
        "\n",
        "# Add a dense output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL7EITA0xJpm",
        "outputId": "dc9ea14a-c053-4f6b-c751-3b57ce1489c7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          320000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 64)               4160      \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 324,225\n",
            "Trainable params: 324,225\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=batch_size, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the model on test data\n",
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyCZKgTKxMNG",
        "outputId": "1a0c50e7-a0b0-41cd-e0ed-4b7670cd837f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 6s 1s/step - loss: 0.7095 - accuracy: 0.5000 - val_loss: 0.7036 - val_accuracy: 0.4993\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.5570 - accuracy: 0.8900 - val_loss: 0.7099 - val_accuracy: 0.5062\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.4295 - accuracy: 0.9500 - val_loss: 0.7170 - val_accuracy: 0.5014\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.3648 - accuracy: 0.9600 - val_loss: 0.7151 - val_accuracy: 0.5068\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.2828 - accuracy: 0.9800 - val_loss: 0.7146 - val_accuracy: 0.5019\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.7197 - val_accuracy: 0.5010\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.1517 - accuracy: 1.0000 - val_loss: 0.7310 - val_accuracy: 0.5001\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.1283 - accuracy: 1.0000 - val_loss: 0.7461 - val_accuracy: 0.5021\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0876 - accuracy: 1.0000 - val_loss: 0.7548 - val_accuracy: 0.5040\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 0.7536 - val_accuracy: 0.5058\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.7559 - accuracy: 0.4997\n",
            "Test score: 0.7558993697166443\n",
            "Test accuracy: 0.49966666102409363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_features = 10000  # Maximum number of words to keep based on word frequency\n",
        "max_len = 150  # Maximum length of reviews (in words) to consider\n",
        "\n",
        "# Load the IMDB dataset\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Cut reviews after max_len words\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add an Embedding layer\n",
        "model.add(Embedding(max_features, 128))  # Use 128-dimensional embedding vectors\n",
        "\n",
        "# Add a Bidirectional LSTM layer\n",
        "model.add(Bidirectional(LSTM(64)))  # Use 64 units in the LSTM layer\n",
        "\n",
        "# Add a Dense output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, batch_size=32, epochs=5, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, batch_size=32)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UuSD1Bmy-rS",
        "outputId": "b8ceb916-dbd4-4a0d-c643-809811e1646f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 215s 268ms/step - loss: 0.3891 - accuracy: 0.8208 - val_loss: 0.3322 - val_accuracy: 0.8612\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 208s 266ms/step - loss: 0.2348 - accuracy: 0.9079 - val_loss: 0.3299 - val_accuracy: 0.8622\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 209s 267ms/step - loss: 0.1612 - accuracy: 0.9384 - val_loss: 0.4191 - val_accuracy: 0.8533\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 201s 257ms/step - loss: 0.1115 - accuracy: 0.9589 - val_loss: 0.3915 - val_accuracy: 0.8596\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 207s 265ms/step - loss: 0.0725 - accuracy: 0.9743 - val_loss: 0.5208 - val_accuracy: 0.8544\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.5208 - accuracy: 0.8544\n",
            "Test loss: 0.5208445191383362\n",
            "Test accuracy: 0.8543999791145325\n"
          ]
        }
      ]
    }
  ]
}